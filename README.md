# Databricks-and-AWS-Data-Engineering-Project

Built an end-to-end Data Engineering pipeline using Databricks (Spark + Delta Lake) and AWS (S3, IAM) to ingest, transform, and model data following Medallion Architecture for scalable analytics.

Engineered PySpark + SQL workflows on Databricks to perform data cleaning, dimensional & fact processing, and enforce schema governance for reliable downstream use.

Automated ETL orchestration and optimized data storage in AWS S3, enabling efficient querying and seamless integration with AWS analytics services.

Delivered curated Delta tables on Databricks with AWS-backed storage (S3), improving query performance, scalability, and downstream BI consumption.
